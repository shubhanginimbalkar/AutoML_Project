{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhanginimbalkar/AutoML_Project/blob/main/MLJar_Pro_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icltiv6EyQZP",
        "outputId": "81b2227e-eec4-43fd-a019-fc03bcf53141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mljar-supervised in /usr/local/lib/python3.10/dist-packages (1.1.12)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (1.26.4)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (1.5.2)\n",
            "Requirement already satisfied: xgboost>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (2.1.1)\n",
            "Requirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (4.5.0)\n",
            "Requirement already satisfied: catboost>=0.24.4 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (1.2.7)\n",
            "Requirement already satisfied: joblib>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (1.4.2)\n",
            "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (3.7.1)\n",
            "Requirement already satisfied: dtreeviz>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (2.2.2)\n",
            "Requirement already satisfied: shap>=0.42.1 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (0.46.0)\n",
            "Requirement already satisfied: seaborn>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (0.13.2)\n",
            "Requirement already satisfied: wordcloud>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (1.9.3)\n",
            "Requirement already satisfied: category-encoders>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (2.6.4)\n",
            "Requirement already satisfied: optuna-integration>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (4.0.0)\n",
            "Requirement already satisfied: mljar-scikit-plot>=0.3.11 in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (0.3.12)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (3.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (4.12.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from mljar-supervised) (7.34.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost>=0.24.4->mljar-supervised) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost>=0.24.4->mljar-supervised) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost>=0.24.4->mljar-supervised) (1.16.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders>=2.2.2->mljar-supervised) (0.14.4)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category-encoders>=2.2.2->mljar-supervised) (0.5.6)\n",
            "Requirement already satisfied: colour in /usr/local/lib/python3.10/dist-packages (from dtreeviz>=2.2.2->mljar-supervised) (0.1.5)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from dtreeviz>=2.2.2->mljar-supervised) (7.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (2.8.2)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from optuna-integration>=3.6.0->mljar-supervised) (4.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->mljar-supervised) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->mljar-supervised) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.5.0->mljar-supervised) (3.5.0)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap>=0.42.1->mljar-supervised) (4.66.5)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from shap>=0.42.1->mljar-supervised) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap>=0.42.1->mljar-supervised) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap>=0.42.1->mljar-supervised) (2.2.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost>=2.0.0->mljar-supervised) (2.23.4)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->mljar-supervised) (71.0.4)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->mljar-supervised) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->mljar-supervised) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->mljar-supervised) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->mljar-supervised) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->mljar-supervised) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->mljar-supervised) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->mljar-supervised) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->mljar-supervised) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->mljar-supervised) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->mljar-supervised) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->mljar-supervised) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mljar-supervised) (0.2.13)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap>=0.42.1->mljar-supervised) (0.43.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration>=3.6.0->mljar-supervised) (1.13.3)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration>=3.6.0->mljar-supervised) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration>=3.6.0->mljar-supervised) (2.0.35)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration>=3.6.0->mljar-supervised) (6.0.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost>=0.24.4->mljar-supervised) (9.0.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->dtreeviz>=2.2.2->mljar-supervised) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->dtreeviz>=2.2.2->mljar-supervised) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->dtreeviz>=2.2.2->mljar-supervised) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->dtreeviz>=2.2.2->mljar-supervised) (2.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration>=3.6.0->mljar-supervised) (1.3.5)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->optuna-integration>=3.6.0->mljar-supervised) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration>=3.6.0->mljar-supervised) (2.1.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mljar-supervised\n",
        "!pip install pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "KfkQTfsAYCR7",
        "outputId": "41e71c07-b448-4a1a-fd63-16d4dcb63044"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 32 fields in line 3971, saw 50\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2dd0d60195d3>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Force columns with mixed types to be read as strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/HomeC.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'column_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Downcast numerical columns to save memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 32 fields in line 3971, saw 50\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load dataset with dtype specified for problematic columns\n",
        "file_path = '/content/HomeC.csv'\n",
        "\n",
        "# Force columns with mixed types to be read as strings\n",
        "data = pd.read_csv(\"/content/HomeC.csv\", dtype={'column_name': 'str'}, low_memory=False)\n",
        "\n",
        "# Downcast numerical columns to save memory\n",
        "def downcast(df):\n",
        "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
        "    int_cols = [c for c in df if df[c].dtype == \"int64\"]\n",
        "    df[float_cols] = df[float_cols].astype(\"float32\")\n",
        "    df[int_cols] = df[int_cols].astype(\"int32\")\n",
        "    return df\n",
        "\n",
        "data = downcast(data)\n",
        "\n",
        "# Handle categorical columns with Label Encoding instead of One-Hot Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in categorical_columns:\n",
        "    data[col] = label_encoder.fit_transform(data[col].astype(str))  # Ensure consistency in data type\n",
        "\n",
        "# Verify memory usage reduction\n",
        "print(data.info())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load dataset with dtype specified for problematic columns\n",
        "file_path = '/content/HomeC.csv'\n",
        "\n",
        "# Force columns with mixed types to be read as strings,\n",
        "# and handle inconsistent number of columns\n",
        "try:\n",
        "    data = pd.read_csv(\"/content/HomeC.csv\", dtype={'column_name': 'str'}, low_memory=False)\n",
        "except pd.errors.ParserError:\n",
        "    # If ParserError occurs due to inconsistent number of columns, use error_bad_lines\n",
        "    data = pd.read_csv(\"/content/HomeC.csv\", dtype={'column_name': 'str'}, low_memory=False, error_bad_lines=False)\n",
        "    print(\"Warning: Rows with inconsistent number of columns were skipped.\")\n",
        "\n",
        "# Downcast numerical columns to save memory\n",
        "def downcast(df):\n",
        "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
        "    int_cols = [c for c in df if df[c].dtype == \"int64\"]\n",
        "    df[float_cols] = df[float_cols].astype(\"float32\")\n",
        "    df[int_cols] = df[int_cols].astype(\"int32\")\n",
        "    return df\n",
        "\n",
        "data = downcast(data)\n",
        "\n",
        "# Handle categorical columns with Label Encoding instead of One-Hot Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in categorical_columns:\n",
        "    data[col] = label_encoder.fit_transform(data[col].astype(str))  # Ensure consistency in data type\n",
        "\n",
        "# Verify memory usage reduction\n",
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "m80kUJHVqT20",
        "outputId": "e9161833-decb-49ca-bbec-7126e5620b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "read_csv() got an unexpected keyword argument 'error_bad_lines'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-4a9ffd0b2053>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/HomeC.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'column_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParserError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 32 fields in line 3971, saw 50\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-4a9ffd0b2053>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParserError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# If ParserError occurs due to inconsistent number of columns, use error_bad_lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/HomeC.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'column_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Warning: Rows with inconsistent number of columns were skipped.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'error_bad_lines'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYHlnQ-f6Ukg",
        "outputId": "dbbfa591-fcfb-4983-a1fe-a87e3e4760b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time                   0\n",
            "use [kW]               0\n",
            "gen [kW]               0\n",
            "House overall [kW]     1\n",
            "Dishwasher [kW]        1\n",
            "Furnace 1 [kW]         1\n",
            "Furnace 2 [kW]         1\n",
            "Home office [kW]       1\n",
            "Fridge [kW]            1\n",
            "Wine cellar [kW]       1\n",
            "Garage door [kW]       1\n",
            "Kitchen 12 [kW]        1\n",
            "Kitchen 14 [kW]        1\n",
            "Kitchen 38 [kW]        1\n",
            "Barn [kW]              1\n",
            "Well [kW]              1\n",
            "Microwave [kW]         1\n",
            "Living room [kW]       1\n",
            "Solar [kW]             1\n",
            "temperature            1\n",
            "icon                   0\n",
            "humidity               1\n",
            "visibility             1\n",
            "summary                0\n",
            "apparentTemperature    1\n",
            "pressure               1\n",
            "windSpeed              1\n",
            "cloudCover             0\n",
            "windBearing            1\n",
            "precipIntensity        1\n",
            "dewPoint               1\n",
            "precipProbability      1\n",
            "dtype: int64\n",
            "time                   0\n",
            "use [kW]               0\n",
            "gen [kW]               0\n",
            "House overall [kW]     0\n",
            "Dishwasher [kW]        0\n",
            "Furnace 1 [kW]         0\n",
            "Furnace 2 [kW]         0\n",
            "Home office [kW]       0\n",
            "Fridge [kW]            0\n",
            "Wine cellar [kW]       0\n",
            "Garage door [kW]       0\n",
            "Kitchen 12 [kW]        0\n",
            "Kitchen 14 [kW]        0\n",
            "Kitchen 38 [kW]        0\n",
            "Barn [kW]              0\n",
            "Well [kW]              0\n",
            "Microwave [kW]         0\n",
            "Living room [kW]       0\n",
            "Solar [kW]             0\n",
            "temperature            0\n",
            "icon                   0\n",
            "humidity               0\n",
            "visibility             0\n",
            "summary                0\n",
            "apparentTemperature    0\n",
            "pressure               0\n",
            "windSpeed              0\n",
            "cloudCover             0\n",
            "windBearing            0\n",
            "precipIntensity        0\n",
            "dewPoint               0\n",
            "precipProbability      0\n",
            "dtype: int64\n",
            "Training set size: (303736, 31)\n",
            "Test set size: (75934, 31)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Step 2: Impute missing values in the feature set and target variable\n",
        "# Fill missing values with the mean for numerical columns\n",
        "data.fillna(data.mean(), inplace=True)\n",
        "\n",
        "# Verify that there are no more missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Redefine X and y after imputation\n",
        "X = data.drop(columns=[target])\n",
        "y = data[target]\n",
        "\n",
        "# Step 3: Split the data into train and test sets again (since we've modified the data)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f'Training set size: {X_train.shape}')\n",
        "print(f'Test set size: {X_test.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUYS4ZG52Wq8",
        "outputId": "48f4c937-62c0-4bc1-8935-a319336ee468"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-cc70cccc7033>:5: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear algorithm was disabled.\n",
            "AutoML directory: AutoML_2\n",
            "The task is regression with evaluation metric rmse\n",
            "AutoML will use algorithms: ['Baseline', 'Decision Tree', 'Random Forest', 'Xgboost', 'Neural Network']\n",
            "AutoML will ensemble available models\n",
            "AutoML steps: ['simple_algorithms', 'default_algorithms', 'ensemble']\n",
            "* Step simple_algorithms will try to check up to 2 models\n",
            "1_Baseline rmse 0.66941 trained in 0.89 seconds\n",
            "2_DecisionTree rmse 0.138533 trained in 16.23 seconds\n",
            "* Step default_algorithms will try to check up to 3 models\n",
            "3_Default_Xgboost rmse 0.042588 trained in 46.55 seconds\n",
            "4_Default_NeuralNetwork rmse 0.001412 trained in 10.18 seconds\n",
            "5_Default_RandomForest rmse 0.069278 trained in 187.79 seconds\n",
            "* Step ensemble will try to check up to 1 model\n",
            "Ensemble rmse 0.001412 trained in 0.42 seconds\n",
            "AutoML fit time: 273.35 seconds\n",
            "AutoML best model: 4_Default_NeuralNetwork\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from supervised.automl import AutoML\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"/content/HomeC.csv\",\n",
        "    skipinitialspace=True,\n",
        ")\n",
        "\n",
        "# Convert all columns to numeric, replacing non-convertible values with NaN\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        try:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        except:\n",
        "            print(f\"Could not convert column {col} to numeric\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[df.columns[:-1]], df['use [kW]'], test_size=0.25\n",
        ")\n",
        "\n",
        "automl = AutoML()\n",
        "automl.fit(X_train, y_train)\n",
        "\n",
        "predictions = automl.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the target column (adjust it based on your objective, e.g., 'use [kW]')\n",
        "target = 'use [kW]'\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = data.drop(columns=[target])\n",
        "y = data[target]\n",
        "\n",
        "# Split the data into train and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f'Training set size: {X_train.shape}')\n",
        "print(f'Test set size: {X_test.shape}')\n",
        "\n",
        "# Initialize AutoML model\n",
        "automl = AutoML()\n",
        "\n",
        "# Fit the model on the training data\n",
        "automl.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = automl.predict(X_test)\n",
        "\n",
        "# Ensure predictions do not contain NaNs\n",
        "predictions = np.nan_to_num(predictions)\n",
        "\n",
        "# Calculate R² score\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "# Print R² value\n",
        "print(f\"R² score: {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB8S5ca2BPup",
        "outputId": "d040647f-5971-45a8-d8c6-b8dd19adfb66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (403128, 31)\n",
            "Test set size: (100783, 31)\n",
            "Linear algorithm was disabled.\n",
            "AutoML directory: AutoML_2\n",
            "The task is regression with evaluation metric rmse\n",
            "AutoML will use algorithms: ['Baseline', 'Decision Tree', 'Random Forest', 'Xgboost', 'Neural Network']\n",
            "AutoML will ensemble available models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/supervised/preprocessing/exclude_missing_target.py:25: UserWarning: There are samples with missing target values in the data which will be excluded for further analysis\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:261: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:280: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML steps: ['simple_algorithms', 'default_algorithms', 'ensemble']\n",
            "* Step simple_algorithms will try to check up to 2 models\n",
            "1_Baseline rmse 1.060787 trained in 1.41 seconds\n",
            "2_DecisionTree rmse 0.188794 trained in 16.85 seconds\n",
            "* Step default_algorithms will try to check up to 3 models\n",
            "3_Default_Xgboost rmse 0.037737 trained in 552.3 seconds\n",
            "4_Default_NeuralNetwork rmse 0.002001 trained in 25.1 seconds\n",
            "5_Default_RandomForest rmse 0.082374 trained in 171.75 seconds\n",
            "* Step ensemble will try to check up to 1 model\n",
            "Ensemble rmse 0.002001 trained in 0.62 seconds\n",
            "AutoML fit time: 782.36 seconds\n",
            "AutoML best model: 4_Default_NeuralNetwork\n",
            "R² score: 0.9999964285774284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the leaderboard to check for column names\n",
        "leaderboard = automl.get_leaderboard()\n",
        "\n",
        "# Print the leaderboard columns\n",
        "print(leaderboard.columns)\n",
        "\n",
        "# Print the top 5 rows of the leaderboard to inspect\n",
        "print(leaderboard.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "_PgAYoz8FIbq",
        "outputId": "4ceb7cd5-0d36-49ab-a2f5-113433a519b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'automl' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7225b703e799>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Inspect the leaderboard to check for column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mleaderboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_leaderboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Print the leaderboard columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaderboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'automl' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Get the leaderboard of models from AutoML\n",
        "leaderboard = automl.get_leaderboard()\n",
        "\n",
        "# Inspect the leaderboard to check the available models\n",
        "print(leaderboard)\n",
        "\n",
        "# Get the top 5 models from the leaderboard\n",
        "top_models = leaderboard['name'].values[:5]  # Assuming 'name' is the correct column for model names\n",
        "\n",
        "# Dictionary to store R² values for each model\n",
        "r2_scores = {}\n",
        "\n",
        "# Loop over each model and calculate R² score\n",
        "for model_name in top_models:\n",
        "    # Get predictions from the specific model (AutoML automatically has them available)\n",
        "    predictions = automl.predict(X_test)  # AutoML always uses the best model for predictions\n",
        "\n",
        "    # Calculate R² score\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "\n",
        "    # Store the R² value\n",
        "    r2_scores[model_name] = r2\n",
        "\n",
        "# Print R² values for all top 5 models\n",
        "for model_name, r2 in r2_scores.items():\n",
        "    print(f\"R² score for model {model_name}: {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bHRW1DkFhKO",
        "outputId": "bece3266-a30b-4a42-d349-135cec01ac71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      name      model_type metric_type  metric_value  \\\n",
            "0               1_Baseline        Baseline        rmse      1.060787   \n",
            "1           2_DecisionTree   Decision Tree        rmse      0.188794   \n",
            "2        3_Default_Xgboost         Xgboost        rmse      0.037737   \n",
            "3  4_Default_NeuralNetwork  Neural Network        rmse      0.002001   \n",
            "4   5_Default_RandomForest   Random Forest        rmse      0.082374   \n",
            "5                 Ensemble        Ensemble        rmse      0.002001   \n",
            "\n",
            "   train_time  \n",
            "0        2.35  \n",
            "1       18.11  \n",
            "2      553.97  \n",
            "3       26.18  \n",
            "4      173.17  \n",
            "5        0.62  \n",
            "R² score for model 1_Baseline: 0.9999964285774284\n",
            "R² score for model 2_DecisionTree: 0.9999964285774284\n",
            "R² score for model 3_Default_Xgboost: 0.9999964285774284\n",
            "R² score for model 4_Default_NeuralNetwork: 0.9999964285774284\n",
            "R² score for model 5_Default_RandomForest: 0.9999964285774284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKICF9_O1G3G",
        "outputId": "0e0d31af-737a-4d2e-ca89-072ae990be3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "models = ['Baseline', 'DecisionTree', 'Default_Xgboost', 'Default_NeuralNetwork', 'Default_RandomForest']\n",
        "scores = [0.9999964285774284] * len(models)  # All models have the same score\n",
        "times = [2.35, 18.11, 553.97, 26.18, 173.17]\n",
        "\n",
        "# Create figure and axes\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "# Create bar plot for scores\n",
        "ax1.bar(models, scores, color='b', alpha=0.6, label='Score')\n",
        "ax1.set_ylabel('Score', color='b')\n",
        "ax1.tick_params(axis='y', labelcolor='b')\n",
        "\n",
        "# Create second y-axis for times\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(models, times, color='r', marker='o', label='Time (s)')\n",
        "ax2.set_ylabel('Time (s)', color='r')\n",
        "ax2.tick_params(axis='y', labelcolor='r')\n",
        "\n",
        "# Title and show\n",
        "plt.title('Model Performance Comparison')\n",
        "fig.tight_layout()  # Adjust layout\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9CA2fpeq4brG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python graph.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFrtLM2s5P7G",
        "outputId": "286d9bbf-5bdd-449b-dffc-7fb75a83db02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/graph.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "models = ['Baseline', 'DecisionTree', 'Default_Xgboost', 'Default_NeuralNetwork', 'Default_RandomForest']\n",
        "scores = [0.9999964285774284] * len(models)  # All models have the same score\n",
        "times = [2.35, 18.11, 553.97, 26.18, 173.17]\n",
        "\n",
        "# Create figure and axes\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "# Create bar plot for scores\n",
        "ax1.bar(models, scores, color='b', alpha=0.6, label='Score')\n",
        "ax1.set_ylabel('Score', color='b')\n",
        "ax1.tick_params(axis='y', labelcolor='b')\n",
        "\n",
        "# Create second y-axis for times\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(models, times, color='r', marker='o', label='Time (s)')\n",
        "ax2.set_ylabel('Time (s)', color='r')\n",
        "ax2.tick_params(axis='y', labelcolor='r')\n",
        "\n",
        "# Title and show\n",
        "plt.title('Model Performance Comparison')\n",
        "fig.tight_layout()  # Adjust layout\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RzQIYOFB43Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python graph.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFPboZ5J4-xW",
        "outputId": "fc5ea136-8ea4-4efb-88ae-65655fd81819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/graph.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python plot_models.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR3uQ2Er5tve",
        "outputId": "fcfee4b5-e2b6-41bc-da9f-34d1d45611e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/plot_models.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# x-coordinates of left sides of bars\n",
        "left = [1, 2, 3, 4, 5]\n",
        "\n",
        "# heights of bars\n",
        "height = [10, 24, 36, 40, 5]\n",
        "\n",
        "# labels for bars\n",
        "tick_label = ['Baseline', 'DecisionTree', 'Default_Xgboost', 'Default_NeuralNetwork', 'Default_RandomForest']\n",
        "\n",
        "# plotting a bar chart\n",
        "plt.bar(left, height, tick_label = tick_label,\n",
        "        width = 0.8, color = ['red', 'green'])\n",
        "\n",
        "# naming the x-axis\n",
        "plt.xlabel('x - axis')\n",
        "# naming the y-axis\n",
        "plt.ylabel('y - axis')\n",
        "# plot title\n",
        "plt.title('My bar chart!')\n",
        "\n",
        "# function to show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jLwVddww6jj4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPL1LWWYq8vYgOUf2ZyMcAO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}